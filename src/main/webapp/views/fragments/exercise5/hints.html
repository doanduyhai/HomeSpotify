<div class="row">
    <h3>Some hints if you're stuck</h3>
    <tabset>
        <tab heading="Scala">
<pre><code class="scala">
case class AlbumByDecadeAndCountry(decade: String, country: String, albumCount: Long)

val sc = buildSparkContext(EXERCISE_5)

val sqlContext: SQLContext = new org.apache.spark.sql.SQLContext(sc)

// Register performers in DataFrame
sqlContext.sql(
    s"""
    |CREATE TEMPORARY TABLE performers
    | USING org.apache.spark.sql.cassandra
    | OPTIONS (
    |   keyspace "$KEYSPACE",
    |   table "$PERFORMERS",
    |   pushdown "true"
    | )
    """.stripMargin)

// Register albums in DataFrame
sqlContext.sql(
    s"""
    |CREATE TEMPORARY TABLE albums
    | USING org.apache.spark.sql.cassandra
    | OPTIONS (
    |   keyspace "$KEYSPACE",
    |   table "$ALBUMS",
    |   pushdown "true"
    | )
    """.stripMargin)

// Register computeDecade() as a DataFrame function
sqlContext.udf.register("computeDecade", computeDecade _)


/*
 * CREATE TABLE IF NOT EXISTS performers (
 *   name TEXT,
 *   ...
 *   country TEXT,
 *   ...
 * );
 *
 *
 * CREATE TABLE IF NOT EXISTS albums (
 *   ...
 *   title TEXT,
 *   year INT,
 *   performer TEXT,
 *   ...
 * );
 *
 *  - SELECT computeDecade(album release year),artist country, count(album title)
 *  - FROM performers & albums JOINING on performers.name=albums.performer
 *  - WHERE performer' country is not null and different than 'Unknown'
 *  - AND album' release year is greater or equal to 1900
 *  - GROUP BY computeDecade(album release year) and artist country
 *  - HAVING count(albums title)>250 to filter out low values count countries
 */

val query: String = """
    SELECT computeDecade(a.???),p.???,count(a.???)
    FROM performers p JOIN albums a
    ON p.??? = a.???
    WHERE p.??? is not null
    AND p.??? != 'Unknown'
    AND a.??? >= 1900
    GROUP BY computeDecade(a.???),p.???
    HAVING count(a.???) > 250
    """.stripMargin

// Execute the SQL statement against Cassandra and Spark
val rows: DataFrame = sqlContext.sql(query)

// Map back the Schema RDD into a triplet (decade,country,count)
rows.map(row => AlbumByDecadeAndCountry(row.getString(0),row.getString(1),row.getLong(2)))
    .saveToCassandra(KEYSPACE, ALBUMS_BY_DECADE_AND_COUNTRY_SQL)

</code></pre>
</tab>
<tab heading="Java 8">
<pre><code class="java">
SparkContext sc = new SparkContext(buildScalaSparkConf(EXERCISE_5));
final JavaSparkContext javaSc = new JavaSparkContext(sc);
final SQLContext sqlContext = new SQLContext(javaSc);


// Register performers in DataFrame
sqlContext.sql("CREATE TEMPORARY TABLE performers" +
                " USING org.apache.spark.sql.cassandra" +
                " OPTIONS (keyspace \"" + Schema.KEYSPACE + "\",  table \"" + Schema.PERFORMERS + "\", pushdown \"true\")");

// Register albums in DataFrame
sqlContext.sql("CREATE TEMPORARY TABLE albums" +
                " USING org.apache.spark.sql.cassandra" +
                " OPTIONS (keyspace \"" + Schema.KEYSPACE + "\",  table \"" + Schema.ALBUMS + "\", pushdown \"true\")");

// Register computeDecade() as a SparkSQL function
// Declare the UDF using the Scala API because of this bug
// https://issues.apache.org/jira/browse/SPARK-9435
sqlContext.udf().register("computeDecade", new Exercise5.ComputeDecadeFn(),
    JavaApiHelper.getTypeTag(String.class),
    JavaApiHelper.getTypeTag(Integer.class));

/*
 * CREATE TABLE IF NOT EXISTS performers (
 *   name TEXT,
 *   ...
 *   country TEXT,
 *   ...
 * );
 *
 *
 * CREATE TABLE IF NOT EXISTS albums (
 *   ...
 *   title TEXT,
 *   year INT,
 *   performer TEXT,
 *   ...
 * );
 *
 *  - SELECT computeDecade(album release year),artist country, count(album title)
 *  - FROM performers & albums JOINING on performers.name=albums.performer
 *  - WHERE performer' country is not null and different than 'Unknown'
 *  - AND album' release year is greater or equal to 1900
 *  - GROUP BY computeDecade(album release year) and artist country
 *  - HAVING count(albums title)>250 to filter out low values count countries
 */


String query = "SELECT computeDecade(a.???),p.???,count(a.???) " +
    " FROM performers p JOIN albums a " +
    " ON p.??? = a.??? " +
    " WHERE p.??? is not null " +
    " AND p.??? != 'Unknown' " +
    " AND a.??? >= 1900 " +
    " GROUP BY computeDecade(a.???),p.??? " +
    " HAVING count(a.???) > 250";

// Execute the SQL statement against Cassandra and Spark
final DataFrame dataFrame = sqlContext.sql(query);

// Map back the DataFrame into a the AlbumByDecadeAndCountry POJO
final JavaRDD&lt;AlbumByDecadeAndCountry&gt; mapped = dataFrame
    .javaRDD()
    .map(row -> new AlbumByDecadeAndCountry(row.getString(0), row.getString(1), new Long(row.getLong(2)).intValue()));

// Save back to Cassandra
javaFunctions(mapped)
    .writerBuilder(KEYSPACE,ALBUMS_BY_DECADE_AND_COUNTRY_SQL,mapToRow(AlbumByDecadeAndCountry.class))
    .saveToCassandra();

</code></pre>
        </tab>
    </tabset>

</div>